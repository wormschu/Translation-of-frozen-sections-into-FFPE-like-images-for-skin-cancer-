# Translation-of-frozen-sections-into-FFPE-like-images-for-skin-cancer-

This repository provides a description of the generative AI framework used for translating frozen section images into FFPE-like representations for accurate assessment of skin cancer resection margins. The objective of this study is to reduce interpretive variability caused by freezing artifacts and improve diagnostic consistency by generating FFPE-like images in real time during surgery.

The associated manuscript describing the methodology, experimental setup, and validation results is currently under peer review.

Models Used in the Study (Unpaired Image Translation)

ğŸ”¹ CycleGAN
ğŸ‘‰ https://github.com/aitorzip/PyTorch-CycleGAN

ğŸ”¹ CUT (Contrastive Unpaired Translation)
ğŸ‘‰ https://github.com/taesungp/contrastive-unpaired-translation

ğŸ”¹ SANTA (Unpaired Image-to-Image Translation With Shortest Path Regularization)
ğŸ‘‰ https://github.com/Mid-Push/santa

ğŸ”¹ AI-FFPE
ğŸ‘‰ https://github.com/DeepMIALab/AI-FFPE

## Final Model
Among the evaluated architectures (CycleGAN, CUT, SANTA, and AI-FFPE), 
CUT demonstrated the best overall performance based on quantitative 
metrics, downstream task evaluation, and qualitative expert assessment.  
Therefore, CUT was selected as the final model for whole-slide generation 
and clinical validation.

## CUT Training Configuration
- Input: 512 Ã— 512 RGB patches  
- Domain A: Frozen section images  
- Domain B: FFPE images  
- Training: Unpaired translation (A â†’ B)

### Optimization
- Optimizer: Adam  
- Î²â‚ = 0.5  
- Î²â‚‚ = 0.999  
- Initial learning rate: 2 Ã— 10â»â´  
- Learning rate schedule: Linear decay  
- GAN objective: Least-Squares GAN (LSGAN)  

### Architecture
- Generator: ResNet blocks  
- Discriminator: PatchGAN  
- Normalization: Instance normalization  
- Loss weights:
  - Î»_GAN = 1.0  
  - Î»_NCE = 1.0  

### Training
- Iterations: 100,000  
